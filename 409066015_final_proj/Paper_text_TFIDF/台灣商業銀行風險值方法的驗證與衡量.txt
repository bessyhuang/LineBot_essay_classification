台灣商業銀行風險值方法的驗證與衡量
The Computation and Evaluation of VaR methods of Commercial Banks in Taiwan
風險值、混合常態分配
由於新巴賽爾資本協定將於2006年底開始正式實施，對於金融業形成莫大的衝擊，使更加地重視風險管理並且積極地建構風險值(Value-at-Risk;VaR)模型，使銀行採取必要的避險措施，以期有效控管銀行風險。因此本研究利用國內銀行的股價報酬率進行來衡量風險值，基於營運狀況的操作型態，根據謝依真(2001)將國內商業銀行依擁有資產投資組合概況與財務報表劃分的五種銀行類型中分別選取遠東商銀、萬泰銀行、中國信託銀行、彰化銀行與農民銀行等5家銀行為代表，以其股價報酬率為實證的對象，同時，為加強本研究的市場實用性，將銀行股價資料區分為雙卡(信用卡與現金卡)卡債風暴(主要期間為2005年7月)前後期兩部分，期望針對影響營運重大事件市場不同變化的趨勢，尋求各種條件下較穩定的風險值計算模式。風險值模擬方法主要是利用歷史模擬法、蒙地卡羅模擬法與變異數-共變異數法來估計台灣商業銀行之報酬率風險值。另外，由於金融商品的報酬率常存在厚尾以及高峰態的特性，因此採用混合常態分配(Mixture of Normal distribution)來替代傳統常態分配。考慮波動隨著時間改變以及波動叢聚性下所造成的厚尾，則採用GARCH(1,1)模型捕捉波動性的變化。在評估與驗證方法的部分，則採用前向測試、LR檢定、Z檢定、條件涵蓋檢定以及RMSE等方法。本研究得到的結論為：在選擇風險值的方法部分，本研究發現不論是卡債風暴前與風暴期間，各銀行在不同條件(窗口與顯著水準的設定)下，其適用之方法不盡相同，並沒有一致較佳的方法，建議各銀行可依內部作業條件、資產分配以及風險管理策略，選用適當風險值方法，做其風險控管與決策。在討論卡債風暴前與風暴期間風險值的變化上，本研究發現中國信託銀行與萬泰銀行在顯著水準為1%時，卡債風暴期間的穿透百分比明顯大於風暴前，表示當在卡債期間之報酬率波動遽增時，掌握尾端風險的能力變差，造成方法的不穩定性，另外中國信託銀行卡債風暴期間的RMSE明顯大於卡債風暴前，表示風暴期間在已造成損失的情況下，損失的狀況較嚴重。在風險值方法的部分，本研究發現混合常態模型在顯著水準越大時，易造成風險值低估，但當報酬率分配左端厚尾現象不明顯時，會發生高估風險值的問題，造成估計誤差；若是右端有明顯厚尾現象，則會造成低估風險值的情形發生。而GARCH法雖然可以反應變異數隨時間波動的問題，但對於突發性的價格(報酬率)的較大或較小變動時，常無法捕捉。另外，也發現較短的窗口配合低顯著水準與較長的窗口配合高顯著水準，此兩種條件都會使得捕捉極端值的績效變差，尤其波動劇烈時，較短的窗口配合低顯著水準會使得低估風險值的狀況更嚴重。
Since the Ministry of Finance in Taiwan has enforced the law「New Basel Capital Accord」at the end of 2006, the markets of all major commercial banks face great challenges. Increased competition and growing pressures for revenue generation have led financial institutions to search for more effective ways to control losses. The importance on risk management to build up VaR models has been emphasized as one of the key issues.This study utilizes return of stock prices of the major commercial banks to measure Value-at-Risk (VaR). Considering various of operation types and conditions of banks, we select five banks from five different types of banks based on  Shieh (2001). In order to enhance the practical applications of this research, we choose the topics of the influence of card-debt problems. We evaluated the accuracy and prediction of VaRs performances estimated by the different models before and during the problems. Furthermore, seeking to find out more stable VaR methods in two different periods influenced by this significant market events.In general, the simulation algorithms are mainly utilized in the historical simulation method, monte carlo simulation method and the variance-covariance method. Since the characteristics of most of financial asset returns hold leptokurtosis and heavy-tailed, we apply mixture of normal distributions method instead of the traditional single component normal distribution assumption. Advance model of the GARCH(1,1) is used to capture the variations of volatility. Finally, we use Forward testing、Binomial test、Kupiec test、Christoffersen test and RMSE to examine the accuracy of the VaRs calculated by the models mentioned above.We find that there is no universal best method to compute VaR value for different types of banks during two different periods or in different conditions (including window sizes and significant levels). To control the risk and make decisions , we suggest that banks could choose proper Value method according its operation environment, allocation of capital assets and strategy of risk management.In the period of card-debt problems, the exception rate of Chinatrust bank and Cosmos bank is higher under 1% significant level. And it exhibits the capability of capturing the tails is worse and unstable because of the increase of the volatility in this period. Besides, in this period, the RMSE of Chinatrust bank is obviously higher, it reveals that in case of causing loss, the situation of loss is more serious.When significant level is higher, mixture of normal distributions method underestimate VaRs more seriously. We also find out when mixing proportion of the left (low) return distribution is small, it would overestimate VaRs and cause the bias of estimation. The GARCH model can successfully capture the trend of volatility but hardly capture the VaRs in the shape change of the volatility.As to issues of assigning window sizes and significance level , we find the two situations small window size with low significant level and big window size with high significant level, would make the performance worse, especially when volatility is heavily fluctuated.
